---
title: "R Notebook"
output: html_notebook
---
```{r}
install.packages(c("purrr", "tidyr"))

```


```{r}
library(rvest)
library(tidyr)
library(dplyr)
library(stringr)
library(plyr)
library(purrr)
```

#先把目標網址整理出來
```{r}
netflix$url <- paste0("https://flixpatrol.com/title/",netflix$url)
```

#抓取排行榜的電影資訊，用 flixpatrol 的資料
```{r}
netflix_urls <- netflix$url 
text_all <-data.frame()

for (i in netflix_urls) {
  print(i)
  
  tryCatch({
    html <- read_html(i, encoding = "UTF-8")
    content <- html_text(html_nodes(html, '.text-gray-500 span'))
    abc <- data.frame(content = content, url = i)
    text_all <- rbind(text_all, abc)
  },
  error = function(e) {
    # 當有錯誤發生（例如網址失效），顯示錯誤訊息並返回空的資料框
    message(paste("Error for URL:", i, "\n", conditionMessage(e)))
    text_all <- rbind(text_all, data.frame(content = NA, url = i))
  })
}

# 最後，你可以檢查抓取到的資料
print(text_all)

```

#抓完資料後，發現每一部作品會在 url 欄出現重複列數，把重複的列unique，並將對應的 content 欄的資訊統整在同一列
```{r}
netflix_test <- text_all %>%
  group_by(url) %>%
  summarise_all(
    list(~toString(unique(.)))
  ) %>%
  distinct(.keep_all = TRUE)

#這個程式碼中的 summarise_all 將所有欄位應用相同的轉換，即將 unique 的值轉換為一個逗號分隔的字串。distinct 保留所有的欄位，確保按照 url 欄位進行分類

merged_netflix <- merge(netflix, netflix_test, by = "url", all = TRUE)

#把 content 是空值的資料fliter出來，人工處理網址，再去抓網頁的資料
netflix_na <- merged_netflix %>% filter(is.na(content)) ##content 沒有資料的
netflix_full <- merged_netflix %>% filter(!is.na(content)) ##content 有資料的

write.csv(netflix_na, file = "netflix_na.csv", row.names = FALSE)
```

#再來試試看空值的資料，抓取網頁資訊
```{r}
netflix_other$url <- paste0("https://flixpatrol.com/title/",netflix_other$url)

netflix_other_urls <- netflix_other$url 
other_all <-data.frame()

for (i in netflix_other_urls) {
  print(i)
  
  tryCatch({
    html <- read_html(i, encoding = "UTF-8")
    content <- html_text(html_nodes(html, '.text-gray-500 span'))
    abc <- data.frame(content = content, url = i)
    other_all <- rbind(other_all, abc)
  },
  error = function(e) {
    # 當有錯誤發生（例如網址失效），顯示錯誤訊息並返回空的資料框
    message(paste("Error for URL:", i, "\n", conditionMessage(e)))
    other_all <- rbind(other_all, data.frame(content = NA, url = i))
  })
}

other_test <- other_all %>%
  group_by(url) %>%
  summarise_all(
    list(~toString(unique(.)))
  ) %>%
  distinct(.keep_all = TRUE)

#這個程式碼中的 summarise_all 將所有欄位應用相同的轉換，即將 unique 的值轉換為一個逗號分隔的字串。distinct 保留所有的欄位，確保按照 url 欄位進行分類

merged_other <- merge(netflix_other, other_test, by = "url", all = TRUE)

##做完之後，還是有3000多列是空值，按上述方式重複操作，盡量把有規則的列都填完
colnames(merged_other)[3] <- 'Title'
colnames(merged_other)[9] <- 'content'
merged_other$`Title 2`=NULL
merged_other$content.x=NULL
netflix_na <- merged_other %>% filter(is.na(content)) ##content 沒有資料的
merged_netflix <- merged_other %>% filter(!is.na(content)) ##content 有資料的
netflix_full <- rbind(netflix_full, merged_netflix) #把所有content有資料合併

write.csv(netflix_na, file = "netflix_na.csv", row.names = FALSE)
```

```{r}
#影集跟電影分開看，算統計
netflix_country<-ddply(netflix_flim,.(country),summarize,count=length(country),Hours_Viewed=sum(Hours_Viewed))

netflix_country<-ddply(netflix_tv,.(country),summarize,count=length(country),Hours_Viewed=sum(Hours_Viewed))

#看台灣電影有哪些
taiwan <- filter(netflix_flim,netflix_flim$country=="Taiwan")

#看N家原創的影片數
Netflix_original_flim<- filter(netflix_flim,netflix_flim$Genres=="Netflix")
Netflix_original_tv<- filter(netflix_tv,netflix_tv$Genres=="Netflix")
#看國家數
original_flim<-ddply(Netflix_original_flim,.(country),summarize,count=length(country),Hours_Viewed=sum(Hours_Viewed))
original_tv<-ddply(Netflix_original_tv,.(country),summarize,count=length(country),Hours_Viewed=sum(Hours_Viewed))

#比較各國原創數量與總觀看時數 vs 影片總數＋總觀看時數
original_flim<-merge(original_flim,netflix_country,by = "country", all = TRUE)
original_tv<-merge(original_tv,netflix_country,by = "country", all = TRUE)

#看台灣電影有哪些
taiwan_tv <- filter(netflix_tv,netflix_tv$country=="Taiwan")

tv_na <- netflix_tv %>% filter(is.na(release_date))

```

#剩下的 3000 多筆資料改用 selenium 抓 imdb 資料
先去終端機打
```{r}
cd /Users/mac/Downloads
java -jar selenium-server-standalone-3.141.59.jar 
```

```{r}
library(RSelenium)
library(rvest)
library(dplyr)
library(seleniumPipes)
library(data.table)
library(stringr)
library(xml2)
```

```{r}
remDr <- remoteDriver(
  remoteServerAddr = "localhost",
  port = 4444,
  browserName = "firefox")
```

#把keywords的court單獨拉出來，成一個獨立的list
```{r}
imdb_list<-filter(netflix_selenium,is.na(title)==FALSE)
```
```{r}
# 開啟網頁
remDr$open()
remDr$navigate("https://www.imdb.com/")

# 創建一個空的 DataFrame 用於存放結果
url_list <- data.frame()

# 從 imdb_list 取得電影名稱列表
imdb <- imdb_list$Title

for (movie_title in imdb_list$Title) {
  # 清除所有 cookies
  remDr$deleteAllCookies()

  # 在搜尋欄輸入電影名稱
  search_box <- remDr$findElement(using = "xpath", '//*[@id="suggestion-search"]')
  search_box$clearElement()
  search_box$sendKeysToElement(list(movie_title))

  # 點擊建議列表的第一個項目
  tryCatch({
    first_suggestion <- remDr$findElement(using = "xpath",  '/html/body/div[2]/nav/div[2]/div[1]/form/div[2]/div/div/div/ul/li[1]/a')
    first_suggestion$clickElement()
  }, error = function(e) {
    message("Error clicking the first suggestion:", conditionMessage(e))
  })
  
  # 等待一段時間，確保頁面載入完成
  Sys.sleep(2)

  # 抓取指定的資訊
  tryCatch({
    webpage<-read_html(remDr$getPageSource()[[1]])
    info_element <-html_nodes(webpage,"[data-testid='title-details-section']")
  
  #開始抓各個資訊
    release_date_text <- html_nodes(info_element, "[data-testid='title-details-releasedate'] a") %>% html_text() %>% .[2]
    country <- html_nodes(info_element, "[data-testid='title-details-origin'] a") %>% html_text()
    
    info_text <- info_element$getElementText()
  }, error = function(e) {
    message("Error fetching information:", conditionMessage(e))
  })

  # 將結果加入 DataFrame
  url_list <- rbind(url_list, data.frame(title = movie_title, content = info_text))
  
}
# 停止 Selenium Server
remDr$close()




```

